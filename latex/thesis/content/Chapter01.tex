\chapter{\rm\bfseries Formal Language Theory}
\label{ch:chapter01}

In computer science, it is common to conflate two distinct notions for a set. The first is a collection sitting on some storage device, e.g., a dataset. The second is a lazy construction: not an explicit collection of objects, but a representation that allows us to efficiently determine membership on demand. This lets us represent infinite sets without requiring an infinite amount of memory. Inclusion then, instead of being simply a lookup query, becomes a decision procedure. This is the basis of formal language theory.

The representation we are chiefly interested in are grammars, which are a common metanotation for specifying the syntactic constraints on programs shared by nearly every programming language. Programming language grammars are overapproximations to the true language of interest, providing a fast procedure for rejecting invalid programs and parsing valid ones.

Like sets, it is possible to abstractly combine languages by manipulating their grammars, mirroring the setwise operations of union, intersection, and difference over languages. These operations are convenient for combining, for example, syntactic and semantic constraints on programs. For example, we might have two grammars representing two properties that are both necessary for a program to be considered valid. We can treat valid programs as a subset of the intersection between the two languages.