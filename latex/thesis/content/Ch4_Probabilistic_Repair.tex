\chapter{\rm\bfseries Probabilistic Program Repair}
\label{ch:chapter03}

As we have seen, the problem of program repair is highly underdetermined. To resolve this ambiguity, we will use a probabilistic model to induce a distribution over the language of valid programs. This distribution will guide the repair process by assigning a likelihood to each possible repair. Then, taking the maximum over all possible repairs, we can find the most likely repair consistent with the constraints and the observed program.

Specifically, we will define an ordering over strings by their likelihood under the probabilistic model. We then define a repair as the most likely string consistent with the observed program and the grammar. We factorize the probability of a string as the product of the probability of each token in the string, conditioned on its predecessors. This allows us to compute the joint probability in a left-to-right fashion.

This probabilistic model will generally admit programs that are locally probable, but globally inconsistent with the grammar. To enforce syntactic validity, we will use the probabilistic language model to ``steer'' a generative sampler through the automaton representing the repair language. This has two advantages: first, it allows us to sample from the repair language incrementally, and second, it ensures that subsequences with high probability are retrieved first, and all trajectories are syntactically valid.

We will consider two kinds of probabilistic models: a constrained Markov model and an unconstrained transformer-based neural network trained on program repair, then evaluate the performance of these models on a syntax repair benchmark consisting of pairwise program transformations. As we will show, the constrained Markov model is able to achieve state-of-the-art precision on blind prediction of the lexical sequence.

Here we give each model 5k+ syntax repairs of varying lengths and Levenshtein distances and measure the precision at varying cutoffs. For example, if the ground truth syntax repair was contained in the top 10 results for half of the repair instances, the model's P@10 would be 50\%.

\begin{figure}[H]
  \resizebox{.24\textwidth}{!}{\input{../popl2025/len_dist_tidy}}
  \resizebox{.24\textwidth}{!}{\input{../popl2025/len_dist_bifi_all}}
  \resizebox{.24\textwidth}{!}{\input{../popl2025/len_dist_s2p}}
  \resizebox{.24\textwidth}{!}{\input{../popl2025/len_dist_bifi}}
  \caption{Total repair precision across the entire test set.}
\end{figure}

If we give it an equivalent number of samples, the constrained Markov model attains an even wider margin.

\begin{figure}[H]
  \resizebox{.24\textwidth}{!}{\input{../popl2025/len_dist_tidy}}
  \resizebox{.24\textwidth}{!}{\input{../popl2025/len_dist_bifi_all}}
  \resizebox{.24\textwidth}{!}{\input{../popl2025/len_dist_tidy200}}
  \resizebox{.24\textwidth}{!}{\input{../popl2025/len_dist_tidy20k}}
  \caption{Sample efficiency increases sharply at larger precision intervals.}
\end{figure}

Next, we measure latency, which attains state-of-the-art precision at about 10 seconds, and additional time results in higher precision.

\begin{figure}[H]
  \begin{center}
%    \resizebox{.19\textwidth}{!}{\input{bar_hillel_repair.tex}}
  \resizebox{.24\textwidth}{!}{\input{../popl2025/bar_hillel_repair_1}}
  \resizebox{.24\textwidth}{!}{\input{../popl2025/bar_hillel_repair_2}}
  \resizebox{.24\textwidth}{!}{\input{../popl2025/bar_hillel_repair_3}}
%    \resizebox{.24\textwidth}{!}{\input{bar_hillel_repair_5}}
%\resizebox{.3\textwidth}{!}{\input{repair1_plot.tex}}
%\resizebox{.307\textwidth}{!}{\input{repair2_plot.tex}}
  \end{center}
  \caption{Latency benchmarks. Note the varying axis ranges. The red line marks Seq2Parse and the orange line marks BIFI's Precision@1.}\label{fig:human}
\end{figure}

\noindent For Precision@k, we measure the precision of our model at top-k prediction out of all instances presented, regardless of outcome. Four outcomes are possible in each repair instance, each a strict subset of the successor.

\begin{enumerate}
  \item $\textsc{Rank}(\sigma') < K$: the top-K sorted results contain the true repair
  \item $\textsc{Dec}(G_\cap) \rightsquigarrow \sigma'$: the true repair is sampled by the decoder
  \item $\sigma' \in \mathcal{L}(G_\cap)$: the true repair is recognized by the intersection grammar
  \item $|G_\cap| < \textsc{MaxHeap}:$ the intersection grammar fits in memory
\end{enumerate}

\noindent Repair cases that pass all four are the ideal, meaning the true repair was sampled and ranked highly, but (1) often fails. This indicates the decoder drew the true repair but was not discerning enough to realize its importance. Cases that fail (2) mean the decoder had the opportunity to, but did not actually draw the true repair, which occurs when the intersection language is too large to fully explore. In rare cases, the decoder was incapable of sampling the true repair, as the JVM ran out of memory. Below, we give a summary of distribution over outcomes across the test set.

\begin{figure}[H]
\begin{center}
\resizebox{.73\textwidth}{!}{\input{../popl2025/sankey}}
\caption{Summarized repair outcomes from the SO Python dataset. (ER=Error, NR=Not recognized, NG=Not generated). Time: $\sim$10h on M1.}
\end{center}
\end{figure}
