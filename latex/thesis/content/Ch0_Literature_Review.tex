\chapter{\rm\bfseries Related Literature}
\label{ch:litreview}

Translating ideas into computer programs demands a high degree of precision, as computers have strict criteria for admitting valid programs. These constraints act as a failsafe against faulty programs and runtime errors, but can be tedious to debug. During the editing process, these constraints are invariably violated by the hasty or inexperienced programmer, requiring manual repair. To assist with this task, automated program repair (APR) attempts to generate possible revisions from which the author may choose. This subject has been closely investigated by programming language research and treated in a number of existing literature reviews~\cite{monperrus2018living, le2021automatic}. We direct our attention primarily towards syntax repair, which attempts to fix parsing errors, the earliest stage in program analysis.

\section{Syntax Repair}

Spellchecking is an early precursor to syntax repair that originates from word processing and seeks to find, among a finite dictionary, the most likely intended revision of a misspelled word~\cite{kernighan1990spelling}. Akin to spellchecking, syntax repair considers the case where this dictionary is not necessarily finite, but rather generated by a grammar representing a potentially infinite collection of words called a language. In the case of programming language syntax, the language and corresponding grammar is typically context-free~\cite{chomsky1959algebraic}.

Various methods have been proposed to handle syntactic program errors, which have been a longstanding open problem since the advent of context-free languages. In 1972, Aho and Peterson~\cite{aho1972minimum} introduce an algorithm that returns a syntactically valid sequence whose distance from the original sequence is minimal. Their method guarantees that a valid repair will be found, but only generates a single repair and does attempt to optimize the naturalness of the generated solution.

While algorithmically elegant, this approach is problematic because source code has both formal and natural characteristics. A pragmatic solution must not merely suggest valid repairs, but also generate suggestions a human is likely to prefer in practice. To model coding conventions and stylistic patterns, researchers have borrowed techniques from natural language processing, but often sacrifice validity, precision or latency as these techniques are prone to misgeneralize and hallucinate syntactically invalid repairs.

Recent work Yasunaga et al.~\cite{yasunaga2021break} and Sakkas et al.~\cite{sakkas2022seq2parse} use natural language models to generate probable fixes, but do not attempt to sample from the space of all and only valid repairs. As a consequence, they have difficulty with inference scaling, where additional test time compute does not translate into improved precision. Furthermore, the generated samples may not even be syntactically valid, as we observe in practice.

Our work addresses all of these concerns. We try to generate every nearby valid program and prioritize the solutions by naturalness, while ensuring response time is tolerable. In other words, we attempt to satisfy soundness, completeness, naturalness and latency simultaneously.


\clearpage