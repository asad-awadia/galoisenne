\chapter{\rm\bfseries Related Literature}
\label{ch:litreview}

Translating ideas into computer programs requires a high degree of precision, as programs have many constraints that must be satisfied in order to be considered valid. These constraints, which are enforced by the compiler or interpreter, can be separated into two broad categories: syntactic and semantic constraints.

\section{Syntactic Repair}

Various strategies have been proposed to handle syntactic program errors, which have been a longstanding open problem since the advent of context-free parsing. In 1972, Aho and Peterson~\cite{aho1972minimum} introduce an algorithm that returns a syntactically valid sequence whose distance from the original sequence is minimal. Their method guarantees that a valid repair will be found, but only selects one and does not produce every valid repair within the same distance.

This approach is problematic, because source code has both formal and natural characteristics. A pragmatic solution must not only suggest valid repairs, but also generate suggestions a human being is liable to write in practice. To model the natural distribution of valid programs, researchers have borrowed techniques from natural language processing to generate natural repairs.

Recent works like Yasunaga et al.~\cite{yasunaga2021break} and Sakkas et al.~\cite{sakkas2022seq2parse} use language models to sample probable fixes, but do not sample from the space of all valid repairs, and have difficulty with inference scaling, where additional test time samples are allowed. Furthermore, the generated samples are not all syntactically valid.

Our work addresses all these concerns. We try to generate all valid programs and prioritize them by naturalness, while ensuring that the latency and response time is minimal. In other words, we target soundness, completeness, naturalness and latency.


\clearpage